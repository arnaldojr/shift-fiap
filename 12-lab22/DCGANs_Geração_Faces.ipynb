{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b170afbf",
   "metadata": {},
   "source": [
    "# DCGANs\n",
    "\n",
    "## refer√™ncia\n",
    "\n",
    "- https://github.com/NSTiwari/DCGANs-using-Keras-and-TensorFlow\n",
    "\n",
    "\n",
    "### Objetivos\n",
    "- Implementar uma DCGAN para gera√ß√£o de faces humanas\n",
    "- Treinar o modelo utilizando o dataset CelebA\n",
    "- Avaliar e gerar novas faces sint√©ticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248377c5",
   "metadata": {},
   "source": [
    "## Importa√ß√£o das Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10843f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas essenciais para o projeto\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# TensorFlow e Keras para Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, array_to_img\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165e5dbb",
   "metadata": {},
   "source": [
    "## Download e Prepara√ß√£o do Dataset CelebA\n",
    "\n",
    "### Sobre o Dataset CelebA\n",
    "- **Nome**: CelebFaces Attributes Dataset\n",
    "- **Tamanho**: Mais de 200.000 imagens de celebridades\n",
    "- **Resolu√ß√£o**: 178√ó218 pixels\n",
    "- **Caracter√≠sticas**: Diversidade √©tnica, idades e express√µes variadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b174bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instalar API do Kaggle\n",
    "# !pip install -q kaggle\n",
    "# !pip install -q kaggle-cli    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14db481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURE SUAS CREDENCIAIS DO KAGGLE\n",
    "os.environ['KAGGLE_USERNAME'] = \"YOUR_KAGGLE_USERNAME\" \n",
    "os.environ['KAGGLE_KEY'] = \"YOUR_KAGGLE_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60ccd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download do dataset CelebA do Kaggle\n",
    "!kaggle datasets download -d jessicali9530/celeba-dataset --unzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62466d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 4.1 An√°lise do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177568a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar diret√≥rio base das imagens\n",
    "BASE_DIR = '/content/img_align_celeba/img_align_celeba'\n",
    "\n",
    "# Obter caminhos de todas as imagens\n",
    "image_paths = []\n",
    "for img_name in os.listdir(BASE_DIR):\n",
    "    image_path = os.path.join(BASE_DIR, img_name)\n",
    "    image_paths.append(image_path)\n",
    "\n",
    "print(f\"Total de imagens encontradas: {len(image_paths):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5a45f5",
   "metadata": {},
   "source": [
    "### 4.2 Redu√ß√£o do Dataset\n",
    "\n",
    "üìù **Justificativa**: O dataset CelebA tem ~202K imagens. Para fins did√°ticos e limita√ß√µes computacionais, vamos usar um subconjunto menor para acelerar o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda7132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover 180.000 imagens para reduzir o dataset\n",
    "SUBSET_SIZE = 180000 \n",
    "imgs_delete = os.listdir('/content/img_align_celeba/img_align_celeba')[:SUBSET_SIZE]\n",
    "\n",
    "print(\"Removendo imagens em excesso...\")\n",
    "for file_ in imgs_delete:\n",
    "    os.remove(os.path.join('/content/img_align_celeba/img_align_celeba', file_))\n",
    "\n",
    "# Atualizar lista de caminhos das imagens restantes\n",
    "image_paths = []\n",
    "for img_name in os.listdir(BASE_DIR):\n",
    "    image_path = os.path.join(BASE_DIR, img_name)\n",
    "    image_paths.append(image_path)\n",
    "\n",
    "print(f\"Imagens restantes: {len(image_paths):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585de68c",
   "metadata": {},
   "source": [
    "### 4.3 Redimensionamento para 64x64\n",
    "\n",
    "#### Por que 64x64 pixels?\n",
    "- **Efici√™ncia computacional**: Menor resolu√ß√£o = treinamento mais r√°pido\n",
    "- **Padr√£o DCGAN**: Facilita o design das camadas (pot√™ncias de 2)\n",
    "- **Estabilidade**: GANs funcionam melhor com resolu√ß√µes moderadas\n",
    "- **Recursos limitados**: Adequado para ambientes com pouca mem√≥ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a43b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar diret√≥rio para imagens redimensionadas\n",
    "%mkdir /content/resized\n",
    "\n",
    "# Redimensionar todas as imagens para 64x64 pixels\n",
    "image_list = []\n",
    "resized_images = []\n",
    "\n",
    "# Carregar imagens originais\n",
    "for filename in glob.glob('/content/img_align_celeba/img_align_celeba/*.jpg'):\n",
    "    img = Image.open(filename)\n",
    "    image_list.append(img)\n",
    "\n",
    "# Redimensionar para 64x64\n",
    "for image in image_list:\n",
    "    image = image.resize((64, 64))\n",
    "    resized_images.append(image)\n",
    "\n",
    "# Salvar imagens redimensionadas\n",
    "for (i, new) in enumerate(resized_images):\n",
    "    new.save('{}{}{}'.format('/content/resized/', i+1, '.jpg'))\n",
    "\n",
    "print(f\"{len(resized_images)} imagens redimensionadas e salvas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d484ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualizar para diret√≥rio de imagens redimensionadas\n",
    "BASE_DIR = '/content/resized'\n",
    "\n",
    "# Obter novos caminhos das imagens redimensionadas\n",
    "image_paths = []\n",
    "for img_name in os.listdir(BASE_DIR):\n",
    "    image_path = os.path.join(BASE_DIR, img_name)\n",
    "    image_paths.append(image_path)\n",
    "\n",
    "print(f\"Imagens redimensionadas dispon√≠veis: {len(image_paths):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb37f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar algumas imagens do dataset\n",
    "plt.figure(figsize=(10, 10))\n",
    "temp_images = image_paths[:25]\n",
    "index = 1\n",
    "\n",
    "for image_path in temp_images:\n",
    "    plt.subplot(5, 5, index)\n",
    "    img = load_img(image_path)\n",
    "    img = np.array(img)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Img {index}', fontsize=8)\n",
    "    index += 1\n",
    "\n",
    "plt.suptitle('Dataset CelebA - Amostras Redimensionadas (64x64)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2498ea5",
   "metadata": {},
   "source": [
    "### 4.4 Normaliza√ß√£o dos Dados\n",
    "\n",
    "**Import√¢ncia da Normaliza√ß√£o**:\n",
    "- O gerador usa ativa√ß√£o `tanh` que produz valores em [-1, 1]\n",
    "- Necess√°rio normalizar as imagens para o mesmo intervalo\n",
    "- F√≥rmula: `(pixel - 127.5) / 127.5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1661dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar imagens em array NumPy\n",
    "print(\"Carregando imagens para array NumPy...\")\n",
    "train_images = [np.array(load_img(path)) for path in tqdm(image_paths)]\n",
    "train_images = np.array(train_images)\n",
    "\n",
    "print(f\"Formato do array: {train_images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de0f933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantir formato correto e tipo float32\n",
    "train_images = train_images.reshape(train_images.shape[0], 64, 64, 3).astype('float32')\n",
    "\n",
    "print(f\"Array reformatado: {train_images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af485b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar imagens para [-1, 1]\n",
    "# Compat√≠vel com ativa√ß√£o tanh do gerador\n",
    "train_images = (train_images - 127.5) / 127.5\n",
    "\n",
    "print(\"Normaliza√ß√£o conclu√≠da!\")\n",
    "print(f\"Valor m√≠nimo: {train_images.min():.3f}\")\n",
    "print(f\"Valor m√°ximo: {train_images.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4baa1a",
   "metadata": {},
   "source": [
    "## Arquitetura das Redes\n",
    "\n",
    "### Hiperpar√¢metros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d629e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LATENT_DIM = 100  # Dimens√£o do ru√≠do de entrada\n",
    "WEIGHT_INIT = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)  # Inicializa√ß√£o dos pesos\n",
    "CHANNELS = 3  # Canais RGB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59697c9",
   "metadata": {},
   "source": [
    "### Arquitetura do Gerador\n",
    "\n",
    "**Evolu√ß√£o das Dimens√µes**:\n",
    "```\n",
    "Ru√≠do 100D ‚Üí Dense ‚Üí 8√ó8√ó512 ‚Üí 16√ó16√ó256 ‚Üí 32√ó32√ó128 ‚Üí 64√ó64√ó64 ‚Üí 64√ó64√ó3\n",
    "```\n",
    "\n",
    "**Componentes**:\n",
    "- Dense + ReLU + Reshape\n",
    "- Conv2DTranspose (upsampling) + ReLU\n",
    "- Conv2D final com ativa√ß√£o Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e98ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir modelo Gerador (ARQUITETURA ORIGINAL)\n",
    "model = Sequential(name='generator')\n",
    "\n",
    "# Camada densa: ru√≠do 1D ‚Üí representa√ß√£o 3D\n",
    "model.add(layers.Dense(8 * 8 * 512, input_dim=LATENT_DIM))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "# Converter 1D para formato 3D\n",
    "model.add(layers.Reshape((8, 8, 512)))\n",
    "\n",
    "# Upsampling para 16x16\n",
    "model.add(layers.Conv2DTranspose(256, (4,4), strides=(2,2), padding='same', kernel_initializer=WEIGHT_INIT))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "# Upsampling para 32x32\n",
    "model.add(layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=WEIGHT_INIT))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "# Upsampling para 64x64\n",
    "model.add(layers.Conv2DTranspose(64, (4,4), strides=(2,2), padding='same', kernel_initializer=WEIGHT_INIT))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "# Camada final: produzir imagem RGB\n",
    "model.add(layers.Conv2D(CHANNELS, (4, 4), padding='same', activation='tanh'))\n",
    "\n",
    "generator = model\n",
    "print(\"Gerador constru√≠do:\")\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533424e4",
   "metadata": {},
   "source": [
    "### 5.3 Arquitetura do Discriminador\n",
    "\n",
    "**Evolu√ß√£o das Dimens√µes**:\n",
    "```\n",
    "Imagem 64√ó64√ó3 ‚Üí 32√ó32√ó64 ‚Üí 16√ó16√ó128 ‚Üí 8√ó8√ó64 ‚Üí Classifica√ß√£o\n",
    "```\n",
    "\n",
    "**Componentes**:\n",
    "- Conv2D + BatchNorm + LeakyReLU\n",
    "- Dropout para regulariza√ß√£o\n",
    "- Dense final com Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb39927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir modelo Discriminador\n",
    "model = Sequential(name='discriminator')\n",
    "input_shape = (64, 64, 3)\n",
    "alpha = 0.2\n",
    "\n",
    "# Primeira camada convolucional\n",
    "model.add(layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same', input_shape=input_shape))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.LeakyReLU(alpha=alpha))\n",
    "\n",
    "# Segunda camada convolucional\n",
    "model.add(layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same', input_shape=input_shape))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.LeakyReLU(alpha=alpha))\n",
    "\n",
    "# Terceira camada convolucional\n",
    "model.add(layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same', input_shape=input_shape))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.LeakyReLU(alpha=alpha))\n",
    "\n",
    "# Flatten e regulariza√ß√£o\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.3))  # Evita discriminador muito forte\n",
    "\n",
    "# Camada de sa√≠da: classifica√ß√£o real/falso\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "discriminator = model\n",
    "print(\"Discriminador constru√≠do:\")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2577c6",
   "metadata": {},
   "source": [
    "## Implementa√ß√£o da DCGAN\n",
    "\n",
    "### Classe DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9483b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe DCGAN original\n",
    "class DCGAN(keras.Model):\n",
    "    def __init__(self, generator, discriminator, latent_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Modelos componentes\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.latent_dim = LATENT_DIM\n",
    "        \n",
    "        # M√©tricas para monitoramento\n",
    "        self.g_loss_metric = keras.metrics.Mean(name='g_loss')\n",
    "        self.d_loss_metric = keras.metrics.Mean(name='d_loss')\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.g_loss_metric, self.d_loss_metric]\n",
    "\n",
    "    def compile(self, g_optimizer, d_optimizer, loss_fn):\n",
    "        super(DCGAN, self).compile() # Chamada ao m√©todo compile da superclasse\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # Obter tamanho do batch\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        \n",
    "        # Gerar ru√≠do aleat√≥rio\n",
    "        random_noise = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # === TREINAR DISCRIMINADOR ===\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Perda com imagens reais\n",
    "            pred_real = self.discriminator(real_images, training=True)\n",
    "            \n",
    "            # Labels para imagens reais (com ru√≠do para estabilidade)\n",
    "            real_labels = tf.ones((batch_size, 1))\n",
    "            real_labels += 0.05 * tf.random.uniform(tf.shape(real_labels))\n",
    "            d_loss_real = self.loss_fn(real_labels, pred_real)\n",
    "\n",
    "            # Perda com imagens falsas\n",
    "            fake_images = self.generator(random_noise)\n",
    "            pred_fake = self.discriminator(fake_images, training=True)\n",
    "            \n",
    "            fake_labels = tf.zeros((batch_size, 1))\n",
    "            d_loss_fake = self.loss_fn(fake_labels, pred_fake)\n",
    "\n",
    "            # Perda total do discriminador\n",
    "            d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "\n",
    "        # Atualizar discriminador\n",
    "        gradients = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "        self.d_optimizer.apply_gradients(zip(gradients, self.discriminator.trainable_variables))\n",
    "\n",
    "        # === TREINAR GERADOR ===\n",
    "        labels = tf.ones((batch_size, 1))\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            # Gerar imagens falsas\n",
    "            fake_images = self.generator(random_noise, training=True)\n",
    "            pred_fake = self.discriminator(fake_images, training=True)\n",
    "            \n",
    "            # Perda do gerador (quer enganar discriminador)\n",
    "            g_loss = self.loss_fn(labels, pred_fake)\n",
    "\n",
    "        # Atualizar gerador\n",
    "        gradients = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(gradients, self.generator.trainable_variables))\n",
    "\n",
    "        # Atualizar m√©tricas\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "\n",
    "        return {'d_loss': self.d_loss_metric.result(), \n",
    "                'g_loss': self.g_loss_metric.result()\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb57ddc",
   "metadata": {},
   "source": [
    "### 6.2 Monitor de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801871f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe para monitorar treinamento visualmente\n",
    "class DCGANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_imgs=25, latent_dim=100):\n",
    "        self.num_imgs = num_imgs\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Ru√≠do fixo para consist√™ncia visual\n",
    "        self.noise = tf.random.normal([25, latent_dim])\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Gerar imagens do gerador\n",
    "        g_img = self.model.generator(self.noise)\n",
    "        \n",
    "        # Desnormalizar para visualiza√ß√£o\n",
    "        g_img = (g_img * 127.5) + 127.5\n",
    "        g_img.numpy()\n",
    "\n",
    "        # Plotar resultados\n",
    "        fig = plt.figure(figsize=(8,8))\n",
    "        for i in range(self.num_imgs):\n",
    "            plt.subplot(5, 5, i+1)\n",
    "            img = array_to_img(g_img[i])\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.suptitle(f'√âpoca {epoch + 1} - Faces Geradas', fontsize=14)\n",
    "        plt.savefig('/content/generated/epoch_{:03d}.png'.format(epoch))\n",
    "        plt.show()\n",
    "        \n",
    "        # Exibir m√©tricas\n",
    "        if logs:\n",
    "            print(f\"√âpoca {epoch + 1}:\")\n",
    "            print(f\"Perda Gerador: {logs['g_loss']:.4f}\")\n",
    "            print(f\"Perda Discriminador: {logs['d_loss']:.4f}\")\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        # Salvar modelo gerador\n",
    "        self.model.generator.save('generator.h5')\n",
    "        print(\"Gerador salvo como 'generator.h5'\")\n",
    "\n",
    "print(\"üëÅÔ∏è Monitor de treinamento configurado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cff166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar diret√≥rio para imagens geradas\n",
    "%mkdir /content/generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e3312d",
   "metadata": {},
   "source": [
    "## Treinamento da DCGAN\n",
    "\n",
    "### Configura√ß√£o dos Otimizadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1492e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar inst√¢ncia da DCGAN\n",
    "dcgan = DCGAN(generator=generator, discriminator=discriminator, latent_dim=LATENT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar otimizadores\n",
    "D_LR = 0.0001  # Taxa de aprendizado do discriminador\n",
    "G_LR = 0.0003  # Taxa de aprendizado do gerador (mais r√°pido)\n",
    "\n",
    "dcgan.compile(\n",
    "    g_optimizer=Adam(learning_rate=G_LR, beta_1=0.5),\n",
    "    d_optimizer=Adam(learning_rate=D_LR, beta_1=0.5),\n",
    "    loss_fn=BinaryCrossentropy()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cc852c",
   "metadata": {},
   "source": [
    "### 7.2 In√≠cio do Treinamento\n",
    "\n",
    "‚è±Ô∏è **Tempo estimado**: 30-60 minutos (dependendo da GPU)\n",
    "\n",
    "üìä **O que observar**:\n",
    "- Perda do gerador diminuindo gradualmente\n",
    "- Perda do discriminador estabilizando em ~0.5\n",
    "- Qualidade visual das faces melhorando progressivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25d100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar treinamento (PAR√ÇMETROS ORIGINAIS)\n",
    "N_EPOCHS = 50\n",
    "\n",
    "# Treinar modelo\n",
    "history = dcgan.fit(\n",
    "    train_images, \n",
    "    epochs=N_EPOCHS, \n",
    "    callbacks=[DCGANMonitor()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e482fb96",
   "metadata": {},
   "source": [
    "## Avalia√ß√£o e Gera√ß√£o de Resultados\n",
    "\n",
    "### An√°lise das M√©tricas de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fb52bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Plota o hist√≥rico de treinamento\"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Perda do gerador\n",
    "    ax1.plot(history.history['g_loss'], label='Gerador', color='blue')\n",
    "    ax1.set_title('Perda do Gerador')\n",
    "    ax1.set_xlabel('√âpoca')\n",
    "    ax1.set_ylabel('Perda')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Perda do discriminador\n",
    "    ax2.plot(history.history['d_loss'], label='Discriminador', color='red')\n",
    "    ax2.set_title('Perda do Discriminador')\n",
    "    ax2.set_xlabel('√âpoca')\n",
    "    ax2.set_ylabel('Perda')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plotar hist√≥rico\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feec7ba",
   "metadata": {},
   "source": [
    "## Gera√ß√£o de Novas Faces\n",
    "\n",
    "### Gerar Nova Face Individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc9796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar uma nova face humana\n",
    "\n",
    "# Criar ru√≠do aleat√≥rio\n",
    "noise = tf.random.normal([1, 100])\n",
    "\n",
    "# Gerar imagem usando gerador treinado\n",
    "g_img = dcgan.generator(noise)\n",
    "\n",
    "# Desnormalizar para visualiza√ß√£o\n",
    "g_img = (g_img * 127.5) + 127.5\n",
    "g_img.numpy()\n",
    "\n",
    "# Converter e exibir\n",
    "img = array_to_img(g_img[0])\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Nova Face Gerada pela DCGAN', fontsize=14, fontweight='bold')\n",
    "plt.savefig('/content/generated/new_image.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e140e757",
   "metadata": {},
   "source": [
    "### 8.2 Galeria de Faces Geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648a5612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar m√∫ltiplas faces\n",
    "\n",
    "num_faces = 16\n",
    "noise_batch = tf.random.normal([num_faces, 100])\n",
    "\n",
    "# Gerar batch de imagens\n",
    "generated_images = dcgan.generator(noise_batch)\n",
    "generated_images = (generated_images * 127.5) + 127.5\n",
    "generated_images = generated_images.numpy()\n",
    "\n",
    "# Plotar galeria\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "fig.suptitle('Faces Geradas', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = array_to_img(generated_images[i])\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'Face {i+1}', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534516ae",
   "metadata": {},
   "source": [
    "## 9. Download dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbee96fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compactar e fazer download dos resultados\n",
    "print(\"Preparando arquivos para download...\")\n",
    "\n",
    "# Compactar imagens geradas\n",
    "!zip -r /content/generated.zip /content/generated\n",
    "\n",
    "# Download dos arquivos\n",
    "files.download('/content/generated.zip')\n",
    "files.download('generator.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
